import requests
import os
import urllib.parse
from bs4 import BeautifulSoup
import random
import string

class ForcedBrowsingScanner:
    def __init__(self):
        self.options = {
            "URL": "",
            "TIMEOUT": "10",
            "DELAY": "0",
            "COOKIE": "",
            "USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "HEADERS": "",
            "RECURSIVE": "False",
            "DEPTH": "2",
            "EXTENSIONS": "php,html,htm,asp,aspx,jsp,js,css,xml,json,txt,conf,bak,old,tmp,log,sql,db",
            "COMMON_FILES": "True",
            "ADMIN_PANELS": "True",
            "BACKUP_FILES": "True",
            "CONFIG_FILES": "True",
            "CUSTOM_WORDLIST": "",
            "RANDOM_AGENT": "False",
            "STEALTH": "False",
            "VERIFY_SSL": "False"
        }
        
        self.common_files = [
            "index.html", "index.htm", "index.php", "default.html", "default.htm", "default.php",
            "home.html", "home.htm", "home.php", "main.html", "main.htm", "main.php",
            "admin.html", "admin.htm", "admin.php", "login.html", "login.htm", "login.php",
            "test.html", "test.htm", "test.php", "temp.html", "temp.htm", "temp.php",
            "backup.html", "backup.htm", "backup.php", "old.html", "old.htm", "old.php",
            "config.html", "config.htm", "config.php", "setup.html", "setup.htm", "setup.php",
            "install.html", "install.htm", "install.php", "maintenance.html", "maintenance.htm", "maintenance.php",
            "robots.txt", "sitemap.xml", "crossdomain.xml", "clientaccesspolicy.xml", ".htaccess",
            ".htpasswd", "web.config", "app.config", "machine.config", "php.ini", ".user.ini",
            "info.php", "phpinfo.php", "test.php", "env.php", "status.php", "health.php",
            "readme.html", "readme.htm", "readme.txt", "README.md", "README.txt", "CHANGELOG.md",
            "LICENSE", "LICENSE.txt", "LICENSE.md", "COPYING", "COPYING.txt", "NOTICE",
            "favicon.ico", "apple-touch-icon.png", "apple-touch-icon-precomposed.png"
        ]
        
        self.admin_panels = [
            "admin", "administrator", "admins", "login", "signin", "wp-login", "wp-admin",
            "cpanel", "panel", "controlpanel", "admincp", "adminpanel", "adminarea",
            "adm", "admin1", "admin2", "admin_login", "admin_login.php", "adminarea.php",
            "adminarea.html", "admin-login", "admin-login.php", "admin-login.html",
            "admincontrol", "admincontrol.php", "adminpanel.php", "adminhome.php",
            "administration", "administration.php", "adminpage.php", "admin.php",
            "manager", "manager.php", "management", "management.php", "adm.php",
            "dashboard", "dashboard.php", "dashboard.html", "user", "user.php",
            "users", "users.php", "login.php", "login.html", "signin.php", "signin.html",
            "logon", "logon.php", "logon.html", "account", "account.php", "account.html",
            "controlpanel", "controlpanel.php", "controlpanel.html", "cp", "cp.php",
            "adminarea", "adminarea.php", "adminarea.html", "webadmin", "webadmin.php",
            "webadmin.html", "adminsite", "adminsite.php", "adminsite.html",
            "sysadmin", "sysadmin.php", "sysadmin.html", "admin1.php", "admin1.html",
            "admin2.php", "admin2.html", "admin-login.php", "admin-login.html",
            "administrator.php", "administrator.html", "moderator", "moderator.php",
            "moderator.html", "moderatorlogin", "moderatorlogin.php", "moderatorlogin.html",
            "superuser", "superuser.php", "superuser.html", "root", "root.php", "root.html"
        ]
        
        self.backup_files = [
            "backup", "backup.sql", "backup.tar", "backup.tar.gz", "backup.zip", "backup.rar",
            "backup.bak", "backup.old", "backup.tmp", "backup.conf", "backup.config",
            "database", "database.sql", "database.tar", "database.tar.gz", "database.zip",
            "database.rar", "database.bak", "database.old", "database.tmp", "database.conf",
            "db", "db.sql", "db.tar", "db.tar.gz", "db.zip", "db.rar", "db.bak", "db.old",
            "db.tmp", "db.conf", "dump", "dump.sql", "dump.tar", "dump.tar.gz", "dump.zip",
            "dump.rar", "dump.bak", "dump.old", "dump.tmp", "dump.conf", "archive",
            "archive.sql", "archive.tar", "archive.tar.gz", "archive.zip", "archive.rar",
            "archive.bak", "archive.old", "archive.tmp", "archive.conf", "sql", "sql.tar",
            "sql.tar.gz", "sql.zip", "sql.rar", "sql.bak", "sql.old", "sql.tmp", "sql.conf",
            "copy", "copy.sql", "copy.tar", "copy.tar.gz", "copy.zip", "copy.rar", "copy.bak",
            "copy.old", "copy.tmp", "copy.conf", "orig", "orig.sql", "orig.tar", "orig.tar.gz",
            "orig.zip", "orig.rar", "orig.bak", "orig.old", "orig.tmp", "orig.conf",
            "original", "original.sql", "original.tar", "original.tar.gz", "original.zip",
            "original.rar", "original.bak", "original.old", "original.tmp", "original.conf"
        ]
        
        self.config_files = [
            "config", "config.php", "config.inc", "config.inc.php", "config.ini", "config.conf",
            "config.json", "config.xml", "config.yml", "config.yaml", "config.bak", "config.old",
            "config.tmp", "configuration", "configuration.php", "configuration.inc",
            "configuration.inc.php", "configuration.ini", "configuration.conf", "configuration.json",
            "configuration.xml", "configuration.yml", "configuration.yaml", "configuration.bak",
            "configuration.old", "configuration.tmp", "settings", "settings.php", "settings.inc",
            "settings.inc.php", "settings.ini", "settings.conf", "settings.json", "settings.xml",
            "settings.yml", "settings.yaml", "settings.bak", "settings.old", "settings.tmp",
            "conf", "conf.php", "conf.inc", "conf.inc.php", "conf.ini", "conf.conf", "conf.json",
            "conf.xml", "conf.yml", "conf.yaml", "conf.bak", "conf.old", "conf.tmp",
            "database", "database.php", "database.inc", "database.inc.php", "database.ini",
            "database.conf", "database.json", "database.xml", "database.yml", "database.yaml",
            "database.bak", "database.old", "database.tmp", "db", "db.php", "db.inc", "db.inc.php",
            "db.ini", "db.conf", "db.json", "db.xml", "db.yml", "db.yaml", "db.bak", "db.old",
            "db.tmp", "env", "env.php", "env.inc", "env.inc.php", "env.ini", "env.conf", "env.json",
            "env.xml", "env.yml", "env.yaml", "env.bak", "env.old", "env.tmp", ".env", ".env.php",
            ".env.inc", ".env.inc.php", ".env.ini", ".env.conf", ".env.json", ".env.xml",
            ".env.yml", ".env.yaml", ".env.bak", ".env.old", ".env.tmp"
        ]
        
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
            "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36"
        ]
        
        self.status_codes = {
            200: "OK",
            201: "Created",
            202: "Accepted",
            204: "No Content",
            301: "Moved Permanently",
            302: "Found",
            303: "See Other",
            307: "Temporary Redirect",
            308: "Permanent Redirect",
            400: "Bad Request",
            401: "Unauthorized",
            403: "Forbidden",
            404: "Not Found",
            405: "Method Not Allowed",
            500: "Internal Server Error",
            501: "Not Implemented",
            502: "Bad Gateway",
            503: "Service Unavailable"
        }
    
    def set_option(self, key, value):
        self.options[key] = value
    
    def get_option(self, key):
        return self.options[key]
    
    def get_headers(self):
        headers = {
            "User-Agent": self.get_option("USER_AGENT")
        }
        
        if self.get_option("RANDOM_AGENT").lower() == "true":
            headers["User-Agent"] = random.choice(self.user_agents)
        
        if self.get_option("COOKIE"):
            headers["Cookie"] = self.get_option("COOKIE")
        
        if self.get_option("HEADERS"):
            try:
                for header in self.get_option("HEADERS").split("\\n"):
                    if ":" in header:
                        key, value = header.split(":", 1)
                        headers[key.strip()] = value.strip()
            except:
                pass
        
        return headers
    
    def get_target_paths(self):
        target_paths = []
        
        if self.get_option("COMMON_FILES").lower() == "true":
            target_paths.extend(self.common_files)
        
        if self.get_option("ADMIN_PANELS").lower() == "true":
            target_paths.extend(self.admin_panels)
        
        if self.get_option("BACKUP_FILES").lower() == "true":
            target_paths.extend(self.backup_files)
        
        if self.get_option("CONFIG_FILES").lower() == "true":
            target_paths.extend(self.config_files)
        
        if self.get_option("CUSTOM_WORDLIST"):
            try:
                with open(self.get_option("CUSTOM_WORDLIST"), "r") as f:
                    target_paths.extend([line.strip() for line in f if line.strip()])
            except:
                pass
        
        extensions = self.get_option("EXTENSIONS").split(",")
        extended_paths = []
        
        for path in target_paths:
            if "." not in path:
                for ext in extensions:
                    extended_paths.append(f"{path}.{ext}")
            else:
                extended_paths.append(path)
        
        return extended_paths
    
    def check_path(self, url, path, headers, timeout):
        try:
            full_url = url.rstrip("/") + "/" + path.lstrip("/")
            
            verify_ssl = self.get_option("VERIFY_SSL").lower() == "true"
            
            response = requests.get(
                full_url,
                headers=headers,
                timeout=int(timeout),
                verify=verify_ssl,
                allow_redirects=False
            )
            
            status_code = response.status_code
            content_length = len(response.content)
            content_type = response.headers.get("Content-Type", "")
            
            return {
                "url": full_url,
                "status_code": status_code,
                "status_text": self.status_codes.get(status_code, "Unknown"),
                "content_length": content_length,
                "content_type": content_type,
                "response_headers": dict(response.headers),
                "found": status_code < 400
            }
        except Exception as e:
            return {
                "url": full_url,
                "status_code": 0,
                "status_text": "Error",
                "content_length": 0,
                "content_type": "",
                "response_headers": {},
                "found": False,
                "error": str(e)
            }
    
    def extract_links(self, url, html_content):
        links = []
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            for link in soup.find_all('a'):
                href = link.get('href')
                if href and href.startswith('/'):
                    links.append(href)
        except:
            pass
        return links
    
    def run(self):
        url = self.get_option("URL")
        timeout = self.get_option("TIMEOUT")
        delay = int(self.get_option("DELAY"))
        recursive = self.get_option("RECURSIVE").lower() == "true"
        depth = int(self.get_option("DEPTH"))
        
        headers = self.get_headers()
        target_paths = self.get_target_paths()
        
        found_resources = []
        
        for path in target_paths:
            if delay > 0:
                time.sleep(delay)
            
            result = self.check_path(url, path, headers, timeout)
            
            if result["found"]:
                found_resources.append(result)
                
                if recursive and depth > 0 and ("text/html" in result.get("content_type", "") or 
                                                "application/xhtml+xml" in result.get("content_type", "")):
                    try:
                        response = requests.get(
                            result["url"],
                            headers=headers,
                            timeout=int(timeout),
                            verify=self.get_option("VERIFY_SSL").lower() == "true"
                        )
                        
                        links = self.extract_links(result["url"], response.text)
                        
                        for link in links:
                            link_result = self.check_path(url, link, headers, timeout)
                            if link_result["found"]:
                                found_resources.append(link_result)
                    except:
                        pass
        
        return {
            "success": True,
            "message": f"Found {len(found_resources)} accessible resources",
            "resources": found_resources
        }
